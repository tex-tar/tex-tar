label_split: [4, 4]
purpose: train
sequence_size: 125
optimizer: adam
lr: 0.0001
model: textar
loss_fn:
  train: train_loss
  val: val_loss
loss_weights:
  - 0.25
  - 0.75
loss_types:
  train: [train_wce,train_wce]
  val: [train_wce,train_wce]
datasets:
  train: /ssd_scratch/rohan.kumar/swaroopajinka/corpus_augmented_strikeout_uands_underlined_copied/T2_125/word_CW/train
  val: /ssd_scratch/rohan.kumar/swaroopajinka/corpus_augmented_strikeout_uands_underlined_copied/T2_125/word_CW/val
  # val: /ssd_scratch/rohan.kumar/swaroopajinka/TEST_SET_TexTAR/WORD_CW_TEST  
bounding_box_label_jsons:
  train: /ssd_scratch/rohan.kumar/swaroopajinka/corpus_augmented_decreased_underlines/train/labels/train_1005_underline_final2--NAME--GT.json
  val: /ssd_scratch/rohan.kumar/swaroopajinka/corpus_augmented_decreased_underlines/val/labels/val_augmented.json  
  # val: /ssd_scratch/rohan.kumar/swaroopajinka/corpus_augmented_decreased_underlines/test/labels/test_augmented_2--NAME--ORIGNAL.json
  # val: /ssd_scratch/rohan.kumar/swaroopajinka/corpus_augmented_decreased_underlines/train/labels/train_1005_underline_final2--NAME--GT.json
batch_size: 1600
pretrained: /home/rohan.kumar/tex-tar/weights-textar-base/textar-base-best_loss.pt
pretrained_function: freeze_backbone
accumulated_batch_descent: 2
dataloader:
  train: DocLevelDataset_RoPE_Train
  val: DocLevelDataset_RoPE_Val_name
num_workers: 8
use_wandb: false
run_name: test-run-1
shuffle: true
wandb_project_name: T1-9Aug
epochs: 100
checkpoint_dir: /home/rohan.kumar/tex-tar/weights
